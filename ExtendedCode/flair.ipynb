{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flair.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Cq2TYc__MkLY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poppingary/name-entity-recognition/blob/main/ExtendedCode/flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq2TYc__MkLY"
      },
      "source": [
        "## Import package and load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OTClsW_HLR3",
        "outputId": "ca63fd4a-07fc-42b9-fd76-34d6b21f3dcb"
      },
      "source": [
        "!pip install --upgrade git+https://github.com/flairNLP/flair.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/flairNLP/flair.git\n",
            "  Cloning https://github.com/flairNLP/flair.git to /tmp/pip-req-build-i0315i3j\n",
            "  Running command git clone -q https://github.com/flairNLP/flair.git /tmp/pip-req-build-i0315i3j\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gdown==3.12.2\n",
            "  Downloading gdown-3.12.2.tar.gz (8.2 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers>=4.0.0\n",
            "  Downloading transformers-4.13.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 8.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 642 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.10) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.10) (4.62.3)\n",
            "Collecting pptree\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading bpemb-0.3.3-py3-none-any.whl (19 kB)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading konoha-4.6.5-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair==0.10) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair==0.10) (2019.12.20)\n",
            "Collecting conllu>=4.0\n",
            "  Downloading conllu-4.4.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting mpld3==0.3\n",
            "  Downloading mpld3-0.3.tar.gz (788 kB)\n",
            "\u001b[K     |████████████████████████████████| 788 kB 73.3 MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "  Downloading Janome-0.4.1-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7 MB 284 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair==0.10) (0.8.9)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading segtok-1.5.10.tar.gz (25 kB)\n",
            "Requirement already satisfied: torch!=1.8,>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.10) (1.10.0+cu111)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair==0.10) (1.0.1)\n",
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 69.0 MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.95\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 73.6 MB/s \n",
            "\u001b[?25hCollecting more-itertools~=8.8.0\n",
            "  Downloading more_itertools-8.8.0-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting wikipedia-api\n",
            "  Downloading Wikipedia-API-0.5.4.tar.gz (18 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair==0.10) (4.2.6)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair==0.10) (3.2.2)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading sqlitedict-1.7.0.tar.gz (28 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair==0.10) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair==0.10) (3.4.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair==0.10) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair==0.10) (1.19.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair==0.10) (1.13.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair==0.10) (5.2.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=3.4.0->flair==0.10) (1.4.1)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
            "Collecting requests\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting importlib-metadata<4.0.0,>=3.7.0\n",
            "  Downloading importlib_metadata-3.10.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair==0.10) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair==0.10) (3.10.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair==0.10) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair==0.10) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair==0.10) (3.0.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair==0.10) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair==0.10) (2.0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair==0.10) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair==0.10) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair==0.10) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair==0.10) (1.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair==0.10) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 35.2 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 43.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair==0.10) (0.2.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair==0.10) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair==0.10) (7.1.2)\n",
            "Building wheels for collected packages: flair, gdown, mpld3, overrides, segtok, sqlitedict, ftfy, langdetect, pptree, wikipedia-api\n",
            "  Building wheel for flair (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flair: filename=flair-0.10-py3-none-any.whl size=288053 sha256=a7fcbcf6fa35da03fb1ada2a636e422a3dc21839cd97beb8297fd6550c666b1f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7e4mzt46/wheels/5b/4d/d7/b9f138537cb1717dc8b96f64c8972b7552d9b9b51296368c43\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-py3-none-any.whl size=9704 sha256=b0fa22f0f38cafd066b609a37d4bc1977edcca2cdd5912b0dc6a57d1f09aa66f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/e0/7e/726e872a53f7358b4b96a9975b04e98113b005cd8609a63abc\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-py3-none-any.whl size=116702 sha256=329b1c3bac74ce65849dae96707718e701c8a9b7a3411773eadc9f43cd53c33e\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/70/6a/1c79e59951a41b4045497da187b2724f5659ca64033cf4548e\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10186 sha256=140ef9bc4faf17ca55dff96f62f6ee65fc9f6f1f637abacfb10fdb60323875ff\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/0d/38/01a9bc6e20dcfaf0a6a7b552d03137558ba1c38aea47644682\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-py3-none-any.whl size=25030 sha256=99660d33b4fbd8615760f29ae4c848cff7c83ebe7b8b248ccc3c33b6997c093a\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/b7/d0/a121106e61339eee5ed083bc230b1c8dc422c49a5a28c2addd\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-py3-none-any.whl size=14392 sha256=a840b2208f6b3cf1977536a9dac824a908dcaca5b66877c8e7d5c45bbd36f70a\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/94/06/18c0e83e9e227da8f3582810b51f319bbfd181e508676a56c8\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=2d279f82831b987fa937d4ebf3afed40de3d1e365be0d9a54736bfc8f3bede2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993242 sha256=fad91af07964a05266ec2ca0de13cdd6af140b28c10b9c496aded1c81bed18ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4629 sha256=a9e8c4954e493593d737c98140ea661801763fb6216e28db6639c2b44c92649e\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/e8/7d/a9c3c19b4722608a0d8b05a38c36bc3f230c43becd2a46794b\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.5.4-py3-none-any.whl size=13475 sha256=2b09fb63cc71541ec51d7867ceb7a485c37ff8ad3399b4ee3dc37f140284eb8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/24/56/58ba93cf78be162451144e7a9889603f437976ef1ae7013d04\n",
            "Successfully built flair gdown mpld3 overrides segtok sqlitedict ftfy langdetect pptree wikipedia-api\n",
            "Installing collected packages: requests, pyyaml, importlib-metadata, tokenizers, sentencepiece, sacremoses, overrides, huggingface-hub, wikipedia-api, transformers, sqlitedict, segtok, pptree, mpld3, more-itertools, langdetect, konoha, janome, gdown, ftfy, deprecated, conllu, bpemb, flair\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.8.2\n",
            "    Uninstalling importlib-metadata-4.8.2:\n",
            "      Successfully uninstalled importlib-metadata-4.8.2\n",
            "  Attempting uninstall: more-itertools\n",
            "    Found existing installation: more-itertools 8.12.0\n",
            "    Uninstalling more-itertools-8.12.0:\n",
            "      Successfully uninstalled more-itertools-8.12.0\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 3.10.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed bpemb-0.3.3 conllu-4.4.1 deprecated-1.2.13 flair-0.10 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.2.1 importlib-metadata-3.10.1 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 more-itertools-8.8.0 mpld3-0.3 overrides-3.1.0 pptree-3.1 pyyaml-6.0 requests-2.26.0 sacremoses-0.0.46 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.3 transformers-4.13.0 wikipedia-api-0.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxpuSSurMmtp"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APe4ByrYMqjI",
        "outputId": "7d09a6b2-c181-4b1a-8dff-e7f691eac17e"
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "tagger = SequenceTagger.load(\"ner-pooled\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-12 20:43:14,129 https://nlp.informatik.hu-berlin.de/resources/models/ner-pooled/en-ner-conll03-pooled-v0.5.pt not found in cache, downloading to /tmp/tmp054igmst\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1125470069/1125470069 [01:04<00:00, 17487334.73B/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-12 20:44:19,006 copying /tmp/tmp054igmst to cache at /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-12 20:44:22,955 removing temp file /tmp/tmp054igmst\n",
            "2021-12-12 20:44:23,116 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQpNR4WONBm6"
      },
      "source": [
        "## Load templates and names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzT6MJkiSC-E",
        "outputId": "f26cdf99-b3b1-4b6f-93f9-8d695528d841"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqvlbbkCNLgF"
      },
      "source": [
        "easy_sentence_templates_file = '/content/drive/MyDrive/IntroToMachineLearning/SentenceSample/SentenceTemplate/easy_sentence_templates.txt'\n",
        "hard_sentence_templates_file = '/content/drive/MyDrive/IntroToMachineLearning/SentenceSample/SentenceTemplate/hard_sentence_templates.txt'\n",
        "common_names_file = '/content/drive/MyDrive/IntroToMachineLearning/SentenceSample/NameSample/common_names.txt'\n",
        "rare_names_file = '/content/drive/MyDrive/IntroToMachineLearning/SentenceSample/NameSample/rare_names.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1l_45xPNYza"
      },
      "source": [
        "def read_template(file):\n",
        "  all_string = ''\n",
        "  with open(file, 'r', encoding='utf-8-sig') as f:\n",
        "    for l in f:\n",
        "      all_string += l\n",
        "  sentences = all_string.split('.')\n",
        "  return [s.strip() + '.' for s in sentences if s != '']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6eEESYWNbdd"
      },
      "source": [
        "def read_name(file):\n",
        "  names = []\n",
        "  with open(file, 'r', encoding='utf-8-sig') as f:\n",
        "    for l in f:\n",
        "      names.append(l.strip())\n",
        "  return names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqTcgLYHNdSF"
      },
      "source": [
        "easy_sentence_templates = read_template(easy_sentence_templates_file)\n",
        "hard_sentence_templates = read_template(hard_sentence_templates_file)\n",
        "common_names = read_name(common_names_file)\n",
        "rare_names = read_name(rare_names_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyYXPx4kNk4b"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEfOJxqiNlqJ"
      },
      "source": [
        "def is_correct(entities, name):\n",
        "    for entity in entities:\n",
        "      if entity.text == name:\n",
        "        if entity.tag == 'PER':\n",
        "          return True\n",
        "        else:\n",
        "          return False\n",
        "\n",
        "def predict_sentences(templates, names):\n",
        "  correct = []\n",
        "  wrong = []\n",
        "\n",
        "  for template in tqdm(templates):\n",
        "    for name in names:\n",
        "      sentence = template.replace('*', name)\n",
        "      sentence_dictionary = Sentence(sentence)\n",
        "      tagger.predict(sentence_dictionary)\n",
        "      entities = sentence_dictionary.get_spans('ner')\n",
        "      if is_correct(entities, name):\n",
        "        correct.append((sentence_dictionary, name))\n",
        "      else:\n",
        "        wrong.append((sentence_dictionary, name))\n",
        "\n",
        "  print('')\n",
        "  print('correct: ' + str(len(correct)))\n",
        "  print('wrong: ' + str(len(wrong)))\n",
        "  print('precision: ' + str(len(correct) / (len(correct) + len(wrong))))\n",
        "\n",
        "  return correct, wrong"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZHIwzO-QfYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f19716a-97e4-46f1-e838-6675afb07053"
      },
      "source": [
        "correct, wrong = predict_sentences(easy_sentence_templates, common_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [04:22<00:00, 17.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "correct: 297\n",
            "wrong: 3\n",
            "precision: 0.99\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HahNy68MQmHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165f14a1-07d0-436c-e5a2-668c683999a7"
      },
      "source": [
        "correct, wrong = predict_sentences(easy_sentence_templates, rare_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [04:15<00:00, 17.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "correct: 293\n",
            "wrong: 7\n",
            "precision: 0.9766666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWZF6TC_Qobi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3326e32-90b5-4562-90b8-354af8066f4d"
      },
      "source": [
        "correct, wrong = predict_sentences(hard_sentence_templates, common_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [07:11<00:00, 28.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "correct: 291\n",
            "wrong: 9\n",
            "precision: 0.97\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVdkUHyYQpwT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a6c6e34-32ff-4459-e200-dbb82cc66610"
      },
      "source": [
        "correct, wrong = predict_sentences(hard_sentence_templates, rare_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 15/15 [07:01<00:00, 28.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "correct: 252\n",
            "wrong: 48\n",
            "precision: 0.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7v7bf5joQpH"
      },
      "source": [
        "def get_per_prob(sent, name):\n",
        "  for t in sent.tokens:\n",
        "    if t.text == name:\n",
        "      s_per = t.get_tags_proba_dist('ner')[10]\n",
        "      assert s_per.value == 'S-PER'\n",
        "      return s_per.score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hy4xcB8eVlEc"
      },
      "source": [
        "def before_memory(temp, names, correct, wrong):\n",
        "  tagger = SequenceTagger.load(\"ner-pooled\")\n",
        "  for name in names:\n",
        "    sent_str = temp.replace('*', name)\n",
        "    sent = Sentence(sent_str)\n",
        "    tagger.predict(sent, all_tag_prob=True)\n",
        "    entities = sent.get_spans('ner')\n",
        "    sPER_score = get_per_prob(sent, name)\n",
        "    if is_correct(entities, name):\n",
        "      correct.append((sent, name, sPER_score))\n",
        "    else:\n",
        "      wrong.append((sent, name, sPER_score))\n",
        "  # print(\"\")\n",
        "  # print(\"correct: \" + str(len(correct)))\n",
        "  # print(\"wrong: \" + str(len(wrong)))\n",
        "  # print(\"precision: \" + str(len(correct)/(len(correct) + len(wrong))))\n",
        "  return correct, wrong "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNpaXB8ErbML"
      },
      "source": [
        "def evaluate(correct, wrong):\n",
        "  def mean_prob(outs):\n",
        "    total_score = 0\n",
        "    for sent, name, score in outs:\n",
        "      total_score += score\n",
        "    return total_score/len(outs)\n",
        "\n",
        "  print(\"correct: \" + str(len(correct)))\n",
        "  print(\"wrong: \" + str(len(wrong)))\n",
        "  print(\"precision: \" + str(len(correct)/(len(correct) + len(wrong))))\n",
        "  print(\"---------------------\")\n",
        "  print(\"correct prob: \" + str(mean_prob(correct)))\n",
        "  print(\"wrong prob: \" + str(mean_prob(wrong)))\n",
        "  print(\"mean prob: \" + str(mean_prob(correct+wrong)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISXQvHp9ZIC4",
        "outputId": "52cae164-8b8a-4a01-e218-e286faf1fbe2"
      },
      "source": [
        "print('Easy sentence with common name\\n')\n",
        "correct = []\n",
        "wrong = []\n",
        "for template in easy_sentence_templates:\n",
        "  correct, wrong = before_memory(template, common_names, correct, wrong)\n",
        "\n",
        "evaluate(correct, wrong)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Easy sentence with common name\n",
            "\n",
            "2021-12-12 21:14:12,534 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:14:30,335 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:14:54,779 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:15:35,175 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:15:55,935 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:16:18,147 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:16:40,702 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:16:59,292 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:17:27,017 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:17:46,897 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:18:05,075 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:18:23,684 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:18:39,814 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:19:01,851 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:19:22,435 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "correct: 295\n",
            "wrong: 5\n",
            "precision: 0.9833333333333333\n",
            "---------------------\n",
            "correct prob: 0.989703665951551\n",
            "wrong prob: 0.1804019592702389\n",
            "mean prob: 0.9762153041735292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL3UnVSzIN_n",
        "outputId": "7c1fdbcf-071f-469b-fd6d-9606ece1ceb6"
      },
      "source": [
        "print('Easy sentence with rare name\\n')\n",
        "correct = []\n",
        "wrong = []\n",
        "for template in easy_sentence_templates:\n",
        "  correct, wrong = before_memory(template, rare_names, correct, wrong)\n",
        "\n",
        "evaluate(correct, wrong)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Easy sentence with rare name\n",
            "\n",
            "2021-12-12 21:19:54,097 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:20:11,126 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:20:35,437 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:21:15,797 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:21:37,146 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:22:00,031 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:22:22,620 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:22:41,719 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:23:08,922 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:23:29,410 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:23:46,751 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:24:05,576 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:24:21,786 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:24:44,625 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:25:04,963 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "correct: 288\n",
            "wrong: 12\n",
            "precision: 0.96\n",
            "---------------------\n",
            "correct prob: 0.9844548153794475\n",
            "wrong prob: 0.08512227248866111\n",
            "mean prob: 0.948481513663816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D4jQXauIat5",
        "outputId": "7ea95661-6f10-4c7c-d6f8-f227785141ec"
      },
      "source": [
        "print('Hard sentence with common name\\n')\n",
        "correct = []\n",
        "wrong = []\n",
        "for template in hard_sentence_templates:\n",
        "  correct, wrong = before_memory(template, common_names, correct, wrong)\n",
        "\n",
        "evaluate(correct, wrong)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hard sentence with common name\n",
            "\n",
            "2021-12-12 21:25:36,461 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:25:57,159 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:26:21,049 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:26:42,441 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:27:01,186 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:27:19,821 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:27:43,120 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:28:30,957 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:29:05,251 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:29:33,726 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:30:14,781 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:31:03,823 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:31:46,327 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:32:46,405 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:33:43,853 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "correct: 288\n",
            "wrong: 12\n",
            "precision: 0.96\n",
            "---------------------\n",
            "correct prob: 0.9307379950017902\n",
            "wrong prob: 0.15437924101327857\n",
            "mean prob: 0.8996836448422497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uW7j_yorIlGp",
        "outputId": "681f20d6-7ae0-448d-9547-1c1c36e37c78"
      },
      "source": [
        "print('Hard sentence with rare name\\n')\n",
        "correct = []\n",
        "wrong = []\n",
        "for template in hard_sentence_templates:\n",
        "  correct, wrong = before_memory(template, rare_names, correct, wrong)\n",
        "\n",
        "evaluate(correct, wrong)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hard sentence with rare name\n",
            "\n",
            "2021-12-12 21:34:19,872 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:34:40,882 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:35:04,538 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:35:25,534 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:35:43,873 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:36:02,127 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:36:25,408 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:37:13,079 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:37:47,186 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:38:15,621 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:38:56,128 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:39:45,344 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:40:27,536 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:41:27,243 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "2021-12-12 21:42:23,875 loading file /root/.flair/models/en-ner-conll03-pooled-v0.5.pt\n",
            "correct: 229\n",
            "wrong: 71\n",
            "precision: 0.7633333333333333\n",
            "---------------------\n",
            "correct prob: 0.9326109188612892\n",
            "wrong prob: 0.14487940514243772\n",
            "mean prob: 0.746181127281161\n"
          ]
        }
      ]
    }
  ]
}